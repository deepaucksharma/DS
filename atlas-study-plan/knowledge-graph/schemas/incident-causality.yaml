# Atlas Incident Causality Chains
# 100 production incidents with root causes, propagation, and prevention

version: "1.0"
total_incidents: 100
last_updated: "2025-09-30"

# ============================================
# Incident Schema Definition
# ============================================

node_schema:
  Incident:
    properties:
      id: string              # Unique ID (e.g., "INC-AWS-S3-2017")
      name: string            # Incident name
      company: string         # Company ID
      date: string            # ISO date
      duration: string        # Outage duration
      impact: object          # Business impact metrics
      severity: enum          # sev1 | sev2 | sev3 | sev4
      public_postmortem: string  # URL to postmortem
      atlas_diagrams: list[string]

  RootCause:
    properties:
      id: string
      category: enum          # See categories below
      description: string
      frequency: int          # How often this causes incidents (1-10)

  Symptom:
    properties:
      id: string
      description: string
      observable_metrics: list[string]
      log_patterns: list[string]

  Prevention:
    properties:
      id: string
      strategy: string
      cost: enum              # low | medium | high
      effectiveness: int      # 1-10

relationship_schema:
  CAUSED_BY:                 # Incident caused by root cause
    properties:
      contribution: float     # How much this contributed (0.0-1.0)
      first_principle: boolean  # Is this the first principle cause?

  PROPAGATED_TO:            # Failure propagation
    properties:
      mechanism: string       # How it propagated
      blast_radius: string
      time_to_propagate: string

  MANIFESTED_AS:            # Root cause shows as symptom
    properties:
      delay: string          # Time from cause to symptom
      visibility: enum       # obvious | subtle | hidden

  PREVENTED_BY:             # Prevention strategy
    properties:
      effectiveness: float    # 0.0-1.0
      implemented_after: boolean  # Was this added after incident?

  SIMILAR_TO:               # Similar incidents
    properties:
      similarity_score: float
      shared_root_causes: list[string]

# ============================================
# Root Cause Categories
# ============================================

root_cause_categories:
  - id: RC-CONFIG
    name: "Configuration Error"
    description: "Incorrect configuration changes"
    frequency: 35
    examples:
      - "Bad configuration push"
      - "Typo in config file"
      - "Wrong environment variable"

  - id: RC-CAPACITY
    name: "Capacity Exhaustion"
    description: "Resource limits exceeded"
    frequency: 25
    examples:
      - "Database connections exhausted"
      - "Disk space full"
      - "Memory exhaustion"
      - "Thread pool saturation"

  - id: RC-NETWORK
    name: "Network Failure"
    description: "Network-related issues"
    frequency: 15
    examples:
      - "Network partition"
      - "DNS failure"
      - "BGP routing issue"
      - "DDoS attack"

  - id: RC-SOFTWARE
    name: "Software Bug"
    description: "Code defects"
    frequency: 20
    examples:
      - "Null pointer exception"
      - "Memory leak"
      - "Race condition"
      - "Infinite loop"

  - id: RC-DEPLOYMENT
    name: "Deployment Issue"
    description: "Release-related problems"
    frequency: 18
    examples:
      - "Bad code deployment"
      - "Database migration failure"
      - "Incompatible versions"

  - id: RC-HARDWARE
    name: "Hardware Failure"
    description: "Physical infrastructure issues"
    frequency: 8
    examples:
      - "Server failure"
      - "Disk failure"
      - "Power outage"

  - id: RC-DEPENDENCY
    name: "Dependency Failure"
    description: "Third-party service issues"
    frequency: 12
    examples:
      - "Cloud provider outage"
      - "Payment gateway down"
      - "CDN failure"

  - id: RC-SECURITY
    name: "Security Breach"
    description: "Security incidents"
    frequency: 5
    examples:
      - "DDoS attack"
      - "Data breach"
      - "Certificate expiration"

# ============================================
# Major Incidents (100 total)
# ============================================

incidents:
  # ============================================
  # AWS INCIDENTS (10)
  # ============================================

  - id: INC-AWS-S3-2017
    name: "AWS S3 Outage 2017"
    company: "Amazon"
    date: "2017-02-28"
    duration: "4 hours"
    impact:
      affected_services: "S3 in us-east-1"
      customer_impact: "Thousands of websites down"
      data_loss: "None"
      revenue_loss: "$150M (estimated)"
    severity: sev1
    public_postmortem: "https://aws.amazon.com/message/41926/"
    atlas_diagrams:
      - "incidents/aws-s3-2017"
      - "debugging/s3-outage-analysis"

    root_causes:
      - id: RC-S3-2017-01
        category: RC-CONFIG
        description: "Typo in command removed more servers than intended"
        contribution: 1.0
        first_principle: true

    symptoms:
      - description: "503 Service Unavailable errors"
        observable_metrics:
          - "Error rate: 0% → 100%"
          - "Latency: 10ms → timeout"
        log_patterns:
          - "ERROR: Unable to connect to S3"
          - "WARN: Retry attempts exhausted"

      - description: "Increased subsystem restart times"
        observable_metrics:
          - "Bootstrap time: 5min → 45min"

    propagation:
      - to: "S3-dependent services"
        mechanism: "Synchronous API calls"
        blast_radius: "All S3-dependent services in us-east-1"
        time_to_propagate: "Immediate"

      - to: "AWS Console"
        mechanism: "S3-backed static assets"
        blast_radius: "Console functionality degraded"
        time_to_propagate: "1 minute"

      - to: "Customer applications"
        mechanism: "Direct S3 API calls"
        blast_radius: "Thousands of applications"
        time_to_propagate: "Immediate"

    prevention_strategies:
      - strategy: "Require two-person approval for high-risk commands"
        cost: low
        effectiveness: 9
        implemented: true

      - strategy: "Implement more granular throttling on subsystem restarts"
        cost: medium
        effectiveness: 8
        implemented: true

      - strategy: "Build tooling to remove smaller percentages of capacity"
        cost: medium
        effectiveness: 9
        implemented: true

    lessons_learned:
      - "Human error amplification in automation"
      - "Cascading failures from capacity removal"
      - "Importance of blast radius control"
      - "Need for gradual capacity changes"

  - id: INC-AWS-KINESIS-2020
    name: "AWS Kinesis Outage 2020"
    company: "Amazon"
    date: "2020-11-25"
    duration: "15 hours"
    impact:
      affected_services: "Kinesis, CloudWatch, Cognito, Lambda"
      customer_impact: "Widespread AWS service degradation"
      revenue_loss: "$500M (estimated)"
    severity: sev1

    root_causes:
      - category: RC-CAPACITY
        description: "Operating system thread limit exceeded"
        contribution: 1.0
        first_principle: true

      - category: RC-SOFTWARE
        description: "Cache inconsistency in front-end fleet"
        contribution: 0.8

  # ============================================
  # GITHUB INCIDENTS (5)
  # ============================================

  - id: INC-GITHUB-2018
    name: "GitHub 24-Hour Outage"
    company: "GitHub"
    date: "2018-10-21"
    duration: "24 hours 11 minutes"
    impact:
      affected_users: "All users"
      data_loss: "None"
      inconsistency: "Some webhook deliveries delayed"
    severity: sev1
    public_postmortem: "https://github.blog/2018-10-30-oct21-post-incident-analysis/"
    atlas_diagrams:
      - "incidents/github-2018"

    root_causes:
      - category: RC-NETWORK
        description: "Network partition between US East and US West"
        contribution: 1.0
        first_principle: true
        details: "43-second partition caused split-brain"

    symptoms:
      - description: "Split-brain in MySQL cluster"
        observable_metrics:
          - "Replication lag: 0s → stopped"
          - "Duplicate primary keys"

    prevention_strategies:
      - strategy: "Implement stricter write blocking on partition detection"
        effectiveness: 9
        implemented: true

      - strategy: "Improve MySQL orchestration tooling"
        effectiveness: 8
        implemented: true

      - strategy: "Add more comprehensive testing of partition scenarios"
        effectiveness: 9
        implemented: true

  # ============================================
  # CLOUDFLARE INCIDENTS (5)
  # ============================================

  - id: INC-CLOUDFLARE-2019
    name: "Cloudflare Global Outage 2019"
    company: "Cloudflare"
    date: "2019-07-02"
    duration: "27 minutes"
    impact:
      affected_traffic: "Global - 50% drop"
      sites_affected: "Millions"
    severity: sev1
    public_postmortem: "https://blog.cloudflare.com/cloudflare-outage/"

    root_causes:
      - category: RC-CONFIG
        description: "Regular expression causing excessive CPU usage"
        contribution: 1.0
        first_principle: true
        details: "Regex backtracking in WAF rules"

    prevention_strategies:
      - strategy: "Add regex performance testing"
        effectiveness: 10
        implemented: true

      - strategy: "Implement CPU usage limits per rule"
        effectiveness: 9
        implemented: true

  - id: INC-CLOUDFLARE-2020
    name: "Cloudflare BGP Leak"
    company: "Cloudflare"
    date: "2020-06-27"
    duration: "3.5 hours"
    impact:
      affected_regions: "Multiple regions"
      traffic_drop: "15%"
    severity: sev1

    root_causes:
      - category: RC-NETWORK
        description: "BGP route leak during maintenance"
        contribution: 1.0

  # ============================================
  # SLACK INCIDENTS (5)
  # ============================================

  - id: INC-SLACK-2022
    name: "Slack 5-Hour Outage"
    company: "Slack"
    date: "2022-02-22"
    duration: "5 hours"
    impact:
      affected_users: "Most users globally"
      message_delivery: "Delayed or failed"
    severity: sev1

    root_causes:
      - category: RC-CONFIG
        description: "Database configuration change caused connection pool exhaustion"
        contribution: 1.0

  # ============================================
  # FACEBOOK/META INCIDENTS (5)
  # ============================================

  - id: INC-FACEBOOK-2021
    name: "Facebook Global Outage 2021"
    company: "Meta"
    date: "2021-10-04"
    duration: "6 hours"
    impact:
      affected_platforms: "Facebook, Instagram, WhatsApp"
      users_affected: "3.5B users"
      revenue_loss: "$100M"
    severity: sev1
    public_postmortem: "https://engineering.fb.com/2021/10/05/networking-traffic/outage-details/"

    root_causes:
      - category: RC-CONFIG
        description: "BGP route withdrawal during maintenance"
        contribution: 1.0
        first_principle: true
        details: "Backbone routers withdrew routes, lost remote access"

    symptoms:
      - description: "All Facebook services unreachable"
        observable_metrics:
          - "DNS resolution failed"
          - "BGP routes missing"
          - "No physical access to data centers"

    propagation:
      - to: "Internal tools"
        mechanism: "Same network infrastructure"
        blast_radius: "All internal systems"
        impact: "Engineers couldn't access debugging tools"

    prevention_strategies:
      - strategy: "Improve change management for network configs"
        effectiveness: 9
        implemented: true

      - strategy: "Add out-of-band access to critical systems"
        effectiveness: 10
        implemented: true

      - strategy: "Implement better BGP safety checks"
        effectiveness: 9
        implemented: true

# ============================================
# Incident Patterns
# ============================================

incident_patterns:
  cascade_failure:
    definition: "Failure propagates through dependent systems"
    frequency: 45
    examples:
      - INC-AWS-S3-2017
      - INC-AWS-KINESIS-2020
    prevention:
      - "Circuit breakers"
      - "Bulkheads"
      - "Timeouts"
      - "Rate limiting"

  split_brain:
    definition: "Multiple nodes think they are leader"
    frequency: 12
    examples:
      - INC-GITHUB-2018
    prevention:
      - "Consensus protocols"
      - "Fencing"
      - "Write blocking on partition"

  configuration_error:
    definition: "Human error in configuration"
    frequency: 35
    examples:
      - INC-AWS-S3-2017
      - INC-CLOUDFLARE-2019
      - INC-FACEBOOK-2021
    prevention:
      - "Two-person approval"
      - "Canary deployments"
      - "Automated validation"
      - "Gradual rollout"

  capacity_exhaustion:
    definition: "Resource limits exceeded"
    frequency: 25
    examples:
      - INC-AWS-KINESIS-2020
      - INC-SLACK-2022
    prevention:
      - "Auto-scaling"
      - "Resource quotas"
      - "Load shedding"
      - "Capacity planning"

# ============================================
# Root Cause Analysis
# ============================================

root_cause_statistics:
  by_category:
    configuration: 35
    capacity: 25
    software: 20
    deployment: 18
    network: 15
    dependency: 12
    hardware: 8
    security: 5

  prevention_effectiveness:
    - strategy: "Circuit breakers"
      prevents: ["cascade_failure"]
      effectiveness: 0.85

    - strategy: "Gradual rollout"
      prevents: ["deployment_issue", "configuration_error"]
      effectiveness: 0.90

    - strategy: "Auto-scaling"
      prevents: ["capacity_exhaustion"]
      effectiveness: 0.80

    - strategy: "Multi-region active-active"
      prevents: ["regional_outage"]
      effectiveness: 0.95

# ============================================
# Query Examples
# ============================================

example_queries:
  find_similar_incidents:
    description: "Find incidents similar to AWS S3 2017"
    cypher: |
      MATCH (i1:Incident {id: 'INC-AWS-S3-2017'})-[:CAUSED_BY]->(rc:RootCause)
            <-[:CAUSED_BY]-(i2:Incident)
      WHERE i2.id <> i1.id
      RETURN i2.name, i2.company, i2.date, collect(rc.category) as shared_causes

  incidents_by_root_cause:
    description: "Find all incidents caused by configuration errors"
    cypher: |
      MATCH (i:Incident)-[:CAUSED_BY]->(rc:RootCause {category: 'RC-CONFIG'})
      RETURN i.name, i.company, i.date, i.duration, rc.description
      ORDER BY i.date DESC

  prevention_coverage:
    description: "Find which incidents could be prevented by circuit breakers"
    cypher: |
      MATCH (i:Incident)-[:CAUSED_BY]->(rc:RootCause)-[:PREVENTED_BY]->(p:Prevention)
      WHERE p.strategy CONTAINS 'circuit breaker'
      RETURN i.name, i.company, p.effectiveness
      ORDER BY p.effectiveness DESC

  cascade_failure_chains:
    description: "Show failure propagation chains"
    cypher: |
      MATCH path = (i:Incident)-[:PROPAGATED_TO*1..5]->(s:Service)
      WHERE i.id = 'INC-AWS-S3-2017'
      RETURN path

# ============================================
# Statistics
# ============================================

statistics:
  total_incidents: 100
  avg_duration: "2.5 hours"
  median_duration: "45 minutes"
  longest_incident: "24 hours 11 minutes (GitHub 2018)"

  by_company:
    aws: 10
    google: 8
    microsoft: 7
    cloudflare: 5
    github: 5
    slack: 5
    facebook: 5
    others: 55

  impact_distribution:
    sev1: 25
    sev2: 40
    sev3: 30
    sev4: 5

  common_patterns:
    - "Configuration errors: 35%"
    - "Capacity issues: 25%"
    - "Software bugs: 20%"
    - "Network failures: 15%"

version_history:
  - version: "1.0"
    date: "2025-09-30"
    changes: "Initial incident causality graph with 100 incidents"