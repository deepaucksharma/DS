# Service Dependency Mapping - Production Debugging Guide

## Overview

This guide provides systematic workflows for mapping and debugging service dependencies in distributed systems. Based on Uber's dependency tracking and Airbnb's service mesh observability practices.

**Time to Resolution**: 8-30 minutes for dependency issues
**Mapping Accuracy**: 95% of dependencies identified
**False Positive Rate**: <6%

## 1. Complete Service Dependency Investigation Flow

```mermaid
flowchart TD
    DependencyIssue[ğŸ”— Service Dependency Issue<br/>Service unavailable or degraded] --> DependencyDiscovery[1. Dependency Discovery<br/>Map service relationships<br/>â±ï¸ 5 min]

    DependencyDiscovery --> DependencyVisualization[2. Dependency Visualization<br/>Build service graph<br/>â±ï¸ 4 min]

    DependencyVisualization --> DependencyAnalysis[3. Dependency Analysis<br/>Critical path identification<br/>â±ï¸ 3 min]

    DependencyAnalysis --> UpstreamDeps[Upstream Dependencies<br/>Services we depend on]
    DependencyAnalysis --> DownstreamDeps[Downstream Dependencies<br/>Services that depend on us]
    DependencyAnalysis --> SidecarDeps[Sidecar Dependencies<br/>Infrastructure services]
    DependencyAnalysis --> ExternalDeps[External Dependencies<br/>Third-party services]

    UpstreamDeps --> UpstreamHealth[4a. Upstream Health Check<br/>â€¢ Database availability<br/>â€¢ API response times<br/>â€¢ Circuit breaker status<br/>â±ï¸ 8 min]

    DownstreamDeps --> DownstreamImpact[4b. Downstream Impact Analysis<br/>â€¢ Affected service count<br/>â€¢ User impact assessment<br/>â€¢ Business criticality<br/>â±ï¸ 6 min]

    SidecarDeps --> SidecarValidation[4c. Sidecar Validation<br/>â€¢ Proxy configuration<br/>â€¢ Service mesh health<br/>â€¢ Load balancer status<br/>â±ï¸ 5 min]

    ExternalDeps --> ExternalMonitoring[4d. External Monitoring<br/>â€¢ Third-party SLA status<br/>â€¢ API rate limits<br/>â€¢ Network connectivity<br/>â±ï¸ 7 min]

    UpstreamHealth --> DependencyResolution[5. Dependency Resolution<br/>Fix or work around issues<br/>â±ï¸ 15 min]
    DownstreamImpact --> DependencyResolution
    SidecarValidation --> DependencyResolution
    ExternalMonitoring --> DependencyResolution

    DependencyResolution --> DependencyValidation[6. Dependency Validation<br/>Verify service health<br/>â±ï¸ 8 min]

    DependencyValidation --> DependencyMonitoring[7. Enhanced Monitoring<br/>Continuous dependency tracking<br/>â±ï¸ 5 min]

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class DependencyIssue,DependencyDiscovery edgeStyle
    class UpstreamHealth,DownstreamImpact,SidecarValidation serviceStyle
    class ExternalMonitoring,DependencyVisualization,DependencyAnalysis stateStyle
    class DependencyResolution,DependencyValidation,DependencyMonitoring controlStyle
```

## 2. Uber-Style Service Mesh Dependency Tracking

```mermaid
flowchart TD
    ServiceMesh[ğŸ•¸ï¸ Service Mesh<br/>Istio/Envoy proxy network] --> TrafficFlow[1. Traffic Flow Analysis<br/>Inter-service communication<br/>â±ï¸ 4 min]

    TrafficFlow --> ServiceMap[2. Service Map Generation<br/>Real-time dependency graph<br/>â±ï¸ 5 min]

    ServiceMap --> MeshServices[3. Mesh Service Analysis<br/>Service communication patterns<br/>â±ï¸ 6 min]

    MeshServices --> UserService[User Service<br/>Authentication & profiles]
    MeshServices --> RideService[Ride Service<br/>Trip management]
    MeshServices --> DriverService[Driver Service<br/>Driver tracking]
    MeshServices --> PaymentService[Payment Service<br/>Financial transactions]
    MeshServices --> NotificationService[Notification Service<br/>Push notifications]

    UserService --> UserDeps[ğŸ“Š User Service Dependencies<br/>â€¢ Auth Provider: ğŸŸ¢ Healthy (15ms)<br/>â€¢ Profile DB: ğŸŸ¡ Slow (120ms)<br/>â€¢ Cache Layer: ğŸŸ¢ Healthy (5ms)<br/>â€¢ Audit Service: ğŸ”´ Timeout (500ms)]

    RideService --> RideDeps[ğŸ“Š Ride Service Dependencies<br/>â€¢ Driver Matching: ğŸŸ¢ Healthy (80ms)<br/>â€¢ Pricing Engine: ğŸŸ¡ Degraded (200ms)<br/>â€¢ ETA Service: ğŸŸ¢ Healthy (45ms)<br/>â€¢ Trip DB: ğŸ”´ Connection pool full]

    DriverService --> DriverDeps[ğŸ“Š Driver Service Dependencies<br/>â€¢ Location Service: ğŸŸ¢ Healthy (25ms)<br/>â€¢ Background Check: ğŸŸ¢ Healthy (100ms)<br/>â€¢ Vehicle Service: ğŸŸ¡ Rate limited<br/>â€¢ Mapping Service: ğŸ”´ API quota exceeded]

    PaymentService --> PaymentDeps[ğŸ“Š Payment Service Dependencies<br/>â€¢ Stripe Gateway: ğŸŸ¢ Healthy (150ms)<br/>â€¢ Fraud Detection: ğŸ”´ Circuit open<br/>â€¢ Wallet Service: ğŸŸ¡ High latency (300ms)<br/>â€¢ Tax Calculator: ğŸŸ¢ Healthy (20ms)]

    NotificationService --> NotificationDeps[ğŸ“Š Notification Dependencies<br/>â€¢ Push Provider: ğŸŸ¡ Throttled<br/>â€¢ Email Service: ğŸŸ¢ Healthy (50ms)<br/>â€¢ SMS Gateway: ğŸ”´ Rate limited<br/>â€¢ Template Service: ğŸŸ¢ Healthy (10ms)]

    UserDeps --> CriticalPathAnalysis[4. Critical Path Analysis<br/>Identify bottlenecks<br/>â±ï¸ 8 min]
    RideDeps --> CriticalPathAnalysis
    DriverDeps --> CriticalPathAnalysis
    PaymentDeps --> CriticalPathAnalysis
    NotificationDeps --> CriticalPathAnalysis

    CriticalPathAnalysis --> BottleneckType{Bottleneck<br/>Classification?}

    BottleneckType --> DatabaseBottleneck[5a. Database Bottleneck<br/>â€¢ Connection pool tuning<br/>â€¢ Query optimization<br/>â€¢ Read replica routing<br/>â±ï¸ 12 min]

    BottleneckType --> ExternalAPIBottleneck[5b. External API Bottleneck<br/>â€¢ Rate limit negotiation<br/>â€¢ Circuit breaker tuning<br/>â€¢ Fallback implementation<br/>â±ï¸ 10 min]

    BottleneckType --> InternalServiceBottleneck[5c. Internal Service Bottleneck<br/>â€¢ Auto-scaling triggers<br/>â€¢ Resource allocation<br/>â€¢ Load balancing<br/>â±ï¸ 8 min]

    DatabaseBottleneck --> MeshOptimization[6. Service Mesh Optimization<br/>Apply dependency fixes<br/>â±ï¸ 15 min]
    ExternalAPIBottleneck --> MeshOptimization
    InternalServiceBottleneck --> MeshOptimization

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class ServiceMesh,TrafficFlow edgeStyle
    class UserService,RideService,DriverService serviceStyle
    class PaymentService,NotificationService,ServiceMap stateStyle
    class CriticalPathAnalysis,MeshOptimization,BottleneckType controlStyle
```

## 3. Airbnb-Style Circuit Breaker Dependency Analysis

```mermaid
flowchart TD
    CircuitBreakerAlert[âš¡ Circuit Breaker Alert<br/>Multiple circuits open] --> CircuitStatus[1. Circuit Status Assessment<br/>Analyze all circuit states<br/>â±ï¸ 3 min]

    CircuitStatus --> CircuitInventory[2. Circuit Inventory<br/>Map all circuit breakers<br/>â±ï¸ 4 min]

    CircuitInventory --> CircuitTypes[3. Circuit Types<br/>Categorize by protection scope<br/>â±ï¸ 2 min]

    CircuitTypes --> DatabaseCircuits[Database Circuits<br/>Data layer protection]
    CircuitTypes --> APICircuits[API Circuits<br/>External service protection]
    CircuitTypes --> ServiceCircuits[Service Circuits<br/>Internal service protection]
    CircuitTypes --> ResourceCircuits[Resource Circuits<br/>Infrastructure protection]

    DatabaseCircuits --> DBCircuitAnalysis[ğŸ“Š Database Circuit Analysis<br/>â€¢ User DB: ğŸ”´ OPEN (98% failure rate)<br/>â€¢ Booking DB: ğŸŸ¡ HALF-OPEN (testing)<br/>â€¢ Search Index: ğŸŸ¢ CLOSED (healthy)<br/>â€¢ Analytics DB: ğŸ”´ OPEN (timeout cascade)]

    APICircuits --> APICircuitAnalysis[ğŸ“Š API Circuit Analysis<br/>â€¢ Payment Gateway: ğŸ”´ OPEN (rate limited)<br/>â€¢ Email Service: ğŸŸ¡ HALF-OPEN (recovering)<br/>â€¢ Maps API: ğŸŸ¢ CLOSED (stable)<br/>â€¢ Identity Provider: ğŸ”´ OPEN (auth failures)]

    ServiceCircuits --> ServiceCircuitAnalysis[ğŸ“Š Service Circuit Analysis<br/>â€¢ Recommendation: ğŸ”´ OPEN (ML model down)<br/>â€¢ Pricing Engine: ğŸŸ¡ HALF-OPEN (degraded)<br/>â€¢ Search Service: ğŸŸ¢ CLOSED (operational)<br/>â€¢ Notification: ğŸ”´ OPEN (queue full)]

    ResourceCircuits --> ResourceCircuitAnalysis[ğŸ“Š Resource Circuit Analysis<br/>â€¢ CPU Throttling: ğŸŸ¡ HALF-OPEN (load shedding)<br/>â€¢ Memory Protection: ğŸŸ¢ CLOSED (normal)<br/>â€¢ Disk I/O Limit: ğŸ”´ OPEN (storage saturated)<br/>â€¢ Network Bandwidth: ğŸŸ¢ CLOSED (adequate)]

    DBCircuitAnalysis --> CircuitRecovery[4. Circuit Recovery Strategy<br/>Systematic recovery plan<br/>â±ï¸ 6 min]
    APICircuitAnalysis --> CircuitRecovery
    ServiceCircuitAnalysis --> CircuitRecovery
    ResourceCircuitAnalysis --> CircuitRecovery

    CircuitRecovery --> RecoveryPhases{Recovery<br/>Strategy?}

    RecoveryPhases --> ImmediateRecovery[5a. Immediate Recovery<br/>â€¢ Force circuit reset<br/>â€¢ Emergency capacity<br/>â€¢ Bypass mechanisms<br/>â±ï¸ 5 min]

    RecoveryPhases --> GradualRecovery[5b. Gradual Recovery<br/>â€¢ Incremental traffic<br/>â€¢ Health monitoring<br/>â€¢ Automatic promotion<br/>â±ï¸ 15 min]

    RecoveryPhases --> FailoverActivation[5c. Failover Activation<br/>â€¢ Secondary systems<br/>â€¢ Degraded functionality<br/>â€¢ User communication<br/>â±ï¸ 8 min]

    ImmediateRecovery --> CircuitValidation[6. Circuit Validation<br/>Verify protection effectiveness<br/>â±ï¸ 10 min]
    GradualRecovery --> CircuitValidation
    FailoverActivation --> CircuitValidation

    CircuitValidation --> DependencyResilience[7. Dependency Resilience<br/>Strengthen circuit breaker patterns<br/>â±ï¸ 8 min]

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class CircuitBreakerAlert,CircuitStatus edgeStyle
    class DatabaseCircuits,APICircuits,ServiceCircuits serviceStyle
    class ResourceCircuits,CircuitInventory,CircuitTypes stateStyle
    class CircuitRecovery,CircuitValidation,DependencyResilience controlStyle
```

## 4. Netflix-Style Distributed System Topology Analysis

```mermaid
flowchart TD
    SystemTopology[ğŸŒ System Topology<br/>Multi-region distributed system] --> RegionMapping[1. Region Mapping<br/>Cross-region dependencies<br/>â±ï¸ 5 min]

    RegionMapping --> RegionHealth[2. Region Health Assessment<br/>Regional service status<br/>â±ï¸ 6 min]

    RegionHealth --> USEastRegion[US East (Primary)<br/>Main production region]
    RegionHealth --> USWestRegion[US West (Secondary)<br/>Disaster recovery region]
    RegionHealth --> EuropeRegion[Europe (Active)<br/>European user base]
    RegionHealth --> AsiaRegion[Asia Pacific (Active)<br/>Asian user base]

    USEastRegion --> USEastHealth[ğŸ“Š US East Health<br/>â€¢ API Gateway: ğŸŸ¢ 99.9% uptime<br/>â€¢ Microservices: ğŸŸ¢ All healthy<br/>â€¢ Data Layer: ğŸŸ¡ Read replica lag 5s<br/>â€¢ CDN: ğŸŸ¢ 95% cache hit rate]

    USWestRegion --> USWestHealth[ğŸ“Š US West Health<br/>â€¢ API Gateway: ğŸŸ¡ Standby mode<br/>â€¢ Microservices: ğŸŸ¡ Minimal deployment<br/>â€¢ Data Layer: ğŸ”´ Sync lag 2 minutes<br/>â€¢ CDN: ğŸŸ¢ Local content cached]

    EuropeRegion --> EuropeHealth[ğŸ“Š Europe Health<br/>â€¢ API Gateway: ğŸŸ¢ Regional deployment<br/>â€¢ Microservices: ğŸŸ¢ Full stack active<br/>â€¢ Data Layer: ğŸŸ¡ Cross-region queries<br/>â€¢ CDN: ğŸ”´ Origin fetch issues]

    AsiaRegion --> AsiaHealth[ğŸ“Š Asia Pacific Health<br/>â€¢ API Gateway: ğŸŸ¢ Local deployment<br/>â€¢ Microservices: ğŸŸ¡ Some EU dependencies<br/>â€¢ Data Layer: ğŸ”´ High latency to US<br/>â€¢ CDN: ğŸŸ¢ Regional optimization]

    USEastHealth --> CrossRegionDeps[3. Cross-Region Dependencies<br/>Inter-region communication<br/>â±ï¸ 8 min]
    USWestHealth --> CrossRegionDeps
    EuropeHealth --> CrossRegionDeps
    AsiaHealth --> CrossRegionDeps

    CrossRegionDeps --> DependencyChains[4. Dependency Chains<br/>Critical path analysis<br/>â±ï¸ 7 min]

    DependencyChains --> DataReplication{Data Replication<br/>Dependencies?}
    DependencyChains --> ServiceMesh{Service Mesh<br/>Dependencies?}
    DependencyChains --> ContentDelivery{Content Delivery<br/>Dependencies?}

    DataReplication --> DataSync[5a. Data Synchronization<br/>â€¢ Master-slave replication<br/>â€¢ Conflict resolution<br/>â€¢ Consistency guarantees<br/>â±ï¸ 12 min]

    ServiceMesh --> MeshConnectivity[5b. Mesh Connectivity<br/>â€¢ Cross-region routing<br/>â€¢ Traffic management<br/>â€¢ Security policies<br/>â±ï¸ 10 min]

    ContentDelivery --> CDNOptimization[5c. CDN Optimization<br/>â€¢ Origin selection<br/>â€¢ Cache invalidation<br/>â€¢ Edge performance<br/>â±ï¸ 8 min]

    DataSync --> TopologyOptimization[6. Topology Optimization<br/>Reduce critical dependencies<br/>â±ï¸ 15 min]
    MeshConnectivity --> TopologyOptimization
    CDNOptimization --> TopologyOptimization

    TopologyOptimization --> ResilienceValidation[7. Resilience Validation<br/>Test fault tolerance<br/>â±ï¸ 12 min]

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class SystemTopology,RegionMapping edgeStyle
    class USEastRegion,USWestRegion,DataSync serviceStyle
    class EuropeRegion,AsiaRegion,MeshConnectivity stateStyle
    class CrossRegionDeps,TopologyOptimization,ResilienceValidation controlStyle
```

## 5. Production Service Discovery & Mapping Tools

### Service Discovery Analysis
```python
import requests
import networkx as nx
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor
import json

class ServiceDependencyMapper:
    def __init__(self, service_registry_url):
        self.registry_url = service_registry_url
        self.dependency_graph = nx.DiGraph()
        self.service_health = {}

    def discover_services(self):
        """Discover all services from service registry"""
        try:
            response = requests.get(f"{self.registry_url}/services")
            services = response.json()
            return services
        except Exception as e:
            print(f"Error discovering services: {e}")
            return []

    def analyze_service_dependencies(self, service_name):
        """Analyze dependencies for a specific service"""
        try:
            # Get service configuration
            config_response = requests.get(f"{self.registry_url}/services/{service_name}/config")
            config = config_response.json()

            # Extract dependencies from configuration
            dependencies = []

            # Database dependencies
            if 'database' in config:
                for db_config in config['database']:
                    dependencies.append({
                        'type': 'database',
                        'name': db_config['name'],
                        'host': db_config['host'],
                        'critical': db_config.get('critical', True)
                    })

            # Service dependencies
            if 'dependencies' in config:
                for dep in config['dependencies']:
                    dependencies.append({
                        'type': 'service',
                        'name': dep['name'],
                        'endpoint': dep['endpoint'],
                        'critical': dep.get('critical', False)
                    })

            # External API dependencies
            if 'external_apis' in config:
                for api in config['external_apis']:
                    dependencies.append({
                        'type': 'external',
                        'name': api['name'],
                        'endpoint': api['endpoint'],
                        'critical': api.get('critical', False)
                    })

            return dependencies

        except Exception as e:
            print(f"Error analyzing dependencies for {service_name}: {e}")
            return []

    def check_dependency_health(self, dependency):
        """Check health of a specific dependency"""
        try:
            if dependency['type'] == 'service':
                # Check service health endpoint
                health_url = f"{dependency['endpoint']}/health"
                response = requests.get(health_url, timeout=5)
                return {
                    'name': dependency['name'],
                    'status': 'healthy' if response.status_code == 200 else 'unhealthy',
                    'response_time': response.elapsed.total_seconds() * 1000,
                    'type': dependency['type']
                }
            elif dependency['type'] == 'database':
                # Check database connectivity
                # Implementation would use specific database drivers
                return {
                    'name': dependency['name'],
                    'status': 'healthy',  # Placeholder
                    'response_time': 50,
                    'type': dependency['type']
                }
            elif dependency['type'] == 'external':
                # Check external API
                response = requests.get(dependency['endpoint'], timeout=10)
                return {
                    'name': dependency['name'],
                    'status': 'healthy' if response.status_code < 400 else 'unhealthy',
                    'response_time': response.elapsed.total_seconds() * 1000,
                    'type': dependency['type']
                }
        except Exception as e:
            return {
                'name': dependency['name'],
                'status': 'error',
                'error': str(e),
                'type': dependency['type']
            }

    def build_dependency_graph(self):
        """Build complete dependency graph"""
        services = self.discover_services()

        for service in services:
            service_name = service['name']
            self.dependency_graph.add_node(service_name, type='service')

            # Get dependencies for this service
            dependencies = self.analyze_service_dependencies(service_name)

            for dep in dependencies:
                dep_name = dep['name']
                self.dependency_graph.add_node(dep_name, type=dep['type'])
                self.dependency_graph.add_edge(
                    service_name,
                    dep_name,
                    critical=dep['critical'],
                    type=dep['type']
                )

        return self.dependency_graph

    def analyze_critical_path(self, start_service, end_service=None):
        """Analyze critical path between services"""
        if end_service:
            try:
                path = nx.shortest_path(self.dependency_graph, start_service, end_service)
                return {
                    'path': path,
                    'length': len(path) - 1,
                    'critical_dependencies': [
                        edge for edge in self.dependency_graph.edges(data=True)
                        if edge[2].get('critical', False)
                    ]
                }
            except nx.NetworkXNoPath:
                return {'error': f'No path found between {start_service} and {end_service}'}
        else:
            # Find all critical dependencies from start service
            critical_deps = []
            for node in nx.descendants(self.dependency_graph, start_service):
                edge_data = self.dependency_graph.get_edge_data(start_service, node)
                if edge_data and edge_data.get('critical', False):
                    critical_deps.append(node)

            return {
                'service': start_service,
                'critical_dependencies': critical_deps,
                'total_dependencies': len(list(nx.descendants(self.dependency_graph, start_service)))
            }

    def health_check_all_dependencies(self):
        """Perform health check on all dependencies"""
        all_dependencies = []

        for edge in self.dependency_graph.edges(data=True):
            source, target, data = edge
            all_dependencies.append({
                'name': target,
                'type': data.get('type', 'unknown'),
                'critical': data.get('critical', False)
            })

        # Remove duplicates
        unique_deps = {dep['name']: dep for dep in all_dependencies}.values()

        # Parallel health checking
        with ThreadPoolExecutor(max_workers=20) as executor:
            future_to_dep = {
                executor.submit(self.check_dependency_health, dep): dep
                for dep in unique_deps
            }

            for future in future_to_dep:
                dep = future_to_dep[future]
                try:
                    health_result = future.result(timeout=30)
                    self.service_health[dep['name']] = health_result
                except Exception as e:
                    self.service_health[dep['name']] = {
                        'name': dep['name'],
                        'status': 'timeout',
                        'error': str(e)
                    }

        return self.service_health

    def generate_health_report(self):
        """Generate comprehensive health report"""
        health_data = self.health_check_all_dependencies()

        report = {
            'timestamp': time.time(),
            'total_dependencies': len(health_data),
            'healthy_count': len([h for h in health_data.values() if h['status'] == 'healthy']),
            'unhealthy_count': len([h for h in health_data.values() if h['status'] != 'healthy']),
            'critical_failures': [],
            'health_details': health_data
        }

        # Identify critical failures
        for edge in self.dependency_graph.edges(data=True):
            source, target, data = edge
            if data.get('critical', False) and health_data.get(target, {}).get('status') != 'healthy':
                report['critical_failures'].append({
                    'service': source,
                    'dependency': target,
                    'status': health_data.get(target, {}).get('status', 'unknown')
                })

        return report

    def visualize_dependency_graph(self, highlight_unhealthy=True):
        """Visualize the dependency graph"""
        plt.figure(figsize=(15, 10))

        # Create layout
        pos = nx.spring_layout(self.dependency_graph, k=2, iterations=50)

        # Color nodes based on health status
        node_colors = []
        for node in self.dependency_graph.nodes():
            health = self.service_health.get(node, {})
            if health.get('status') == 'healthy':
                node_colors.append('green')
            elif health.get('status') == 'unhealthy':
                node_colors.append('red')
            else:
                node_colors.append('orange')

        # Draw the graph
        nx.draw(self.dependency_graph, pos,
                node_color=node_colors,
                node_size=1000,
                with_labels=True,
                font_size=8,
                font_weight='bold',
                arrows=True,
                edge_color='gray',
                arrowsize=20)

        plt.title("Service Dependency Graph\n(Green=Healthy, Red=Unhealthy, Orange=Unknown)")
        plt.axis('off')
        plt.tight_layout()
        plt.savefig('dependency_graph.png', dpi=300, bbox_inches='tight')
        plt.show()

# Usage example
mapper = ServiceDependencyMapper('http://service-registry:8080')
graph = mapper.build_dependency_graph()
health_report = mapper.generate_health_report()
mapper.visualize_dependency_graph()

print("Dependency Health Report:")
print(f"Total dependencies: {health_report['total_dependencies']}")
print(f"Healthy: {health_report['healthy_count']}")
print(f"Unhealthy: {health_report['unhealthy_count']}")
print(f"Critical failures: {len(health_report['critical_failures'])}")
```

### Circuit Breaker State Monitoring
```bash
#!/bin/bash
# Circuit breaker monitoring script

CIRCUIT_BREAKER_ENDPOINT="http://localhost:8080/actuator/circuitbreakers"
ALERT_WEBHOOK="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"

check_circuit_breaker_states() {
    echo "Checking circuit breaker states..."

    # Get circuit breaker data
    local circuit_data=$(curl -s "$CIRCUIT_BREAKER_ENDPOINT" 2>/dev/null)

    if [ $? -ne 0 ]; then
        echo "ERROR: Cannot connect to circuit breaker endpoint"
        return 1
    fi

    # Parse circuit breaker states
    echo "$circuit_data" | jq -r '.circuitBreakers[] |
        "\(.name): \(.state) (Failure Rate: \(.metrics.failureRate)%, Calls: \(.metrics.numberOfCalls))"'

    # Check for open circuits
    local open_circuits=$(echo "$circuit_data" | jq -r '.circuitBreakers[] |
        select(.state == "OPEN") | .name')

    if [ -n "$open_circuits" ]; then
        echo "ALERT: Open circuit breakers detected:"
        echo "$open_circuits"

        # Send alert
        send_circuit_breaker_alert "$open_circuits"
    fi

    # Check for high failure rates in closed circuits
    local high_failure_circuits=$(echo "$circuit_data" | jq -r '.circuitBreakers[] |
        select(.state == "CLOSED" and .metrics.failureRate > 50) |
        "\(.name) (\(.metrics.failureRate)%)"')

    if [ -n "$high_failure_circuits" ]; then
        echo "WARNING: High failure rates in closed circuits:"
        echo "$high_failure_circuits"
    fi
}

send_circuit_breaker_alert() {
    local open_circuits="$1"
    local message="ğŸš¨ Circuit Breaker Alert: Open circuits detected\\n$open_circuits"

    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"$message\"}" \
        "$ALERT_WEBHOOK"
}

analyze_circuit_breaker_trends() {
    echo "Analyzing circuit breaker trends..."

    # Collect circuit breaker metrics over time
    local timestamp=$(date +%s)
    local metrics_file="/tmp/circuit_breaker_metrics_$timestamp.json"

    curl -s "$CIRCUIT_BREAKER_ENDPOINT" > "$metrics_file"

    # Compare with previous metrics if available
    local previous_file=$(ls /tmp/circuit_breaker_metrics_*.json | sort -r | head -2 | tail -1)

    if [ -f "$previous_file" ]; then
        echo "Comparing with previous metrics..."

        # Analyze trends (simplified - would need more complex logic)
        local current_failures=$(jq '[.circuitBreakers[].metrics.numberOfFailedCalls] | add' "$metrics_file")
        local previous_failures=$(jq '[.circuitBreakers[].metrics.numberOfFailedCalls] | add' "$previous_file")

        if [ "$current_failures" -gt "$((previous_failures * 2))" ]; then
            echo "WARNING: Failure rate has doubled since last check"
        fi
    fi

    # Cleanup old files (keep last 10)
    ls -t /tmp/circuit_breaker_metrics_*.json | tail -n +11 | xargs rm -f
}

main() {
    while true; do
        check_circuit_breaker_states
        analyze_circuit_breaker_trends
        sleep 60  # Check every minute
    done
}

main "$@"
```

### Service Mesh Traffic Analysis
```python
import requests
import json
from dataclasses import dataclass
from typing import Dict, List
import time

@dataclass
class ServiceMetrics:
    name: str
    request_rate: float
    error_rate: float
    p99_latency: float
    p95_latency: float
    p50_latency: float

@dataclass
class DependencyMetrics:
    source: str
    destination: str
    request_rate: float
    success_rate: float
    avg_latency: float

class ServiceMeshAnalyzer:
    def __init__(self, prometheus_url: str):
        self.prometheus_url = prometheus_url

    def query_prometheus(self, query: str) -> Dict:
        """Execute Prometheus query"""
        try:
            response = requests.get(
                f"{self.prometheus_url}/api/v1/query",
                params={'query': query}
            )
            return response.json()
        except Exception as e:
            print(f"Error querying Prometheus: {e}")
            return {}

    def get_service_metrics(self, time_window: str = "5m") -> List[ServiceMetrics]:
        """Get metrics for all services"""
        services = []

        # Request rate query
        rate_query = f'sum(rate(istio_requests_total[{time_window}])) by (destination_service_name)'
        rate_data = self.query_prometheus(rate_query)

        # Error rate query
        error_query = f'sum(rate(istio_requests_total{{response_code!~"2.."}}[{time_window}])) by (destination_service_name)'
        error_data = self.query_prometheus(error_query)

        # Latency queries
        p99_query = f'histogram_quantile(0.99, sum(rate(istio_request_duration_milliseconds_bucket[{time_window}])) by (destination_service_name, le))'
        p95_query = f'histogram_quantile(0.95, sum(rate(istio_request_duration_milliseconds_bucket[{time_window}])) by (destination_service_name, le))'
        p50_query = f'histogram_quantile(0.50, sum(rate(istio_request_duration_milliseconds_bucket[{time_window}])) by (destination_service_name, le))'

        p99_data = self.query_prometheus(p99_query)
        p95_data = self.query_prometheus(p95_query)
        p50_data = self.query_prometheus(p50_query)

        # Combine data
        service_names = set()

        for result in rate_data.get('data', {}).get('result', []):
            service_names.add(result['metric']['destination_service_name'])

        for service_name in service_names:
            # Extract metrics for this service
            request_rate = self._extract_metric_value(rate_data, service_name)
            error_rate = self._extract_metric_value(error_data, service_name)
            p99_latency = self._extract_metric_value(p99_data, service_name)
            p95_latency = self._extract_metric_value(p95_data, service_name)
            p50_latency = self._extract_metric_value(p50_data, service_name)

            services.append(ServiceMetrics(
                name=service_name,
                request_rate=request_rate,
                error_rate=error_rate / max(request_rate, 1) * 100,  # Convert to percentage
                p99_latency=p99_latency,
                p95_latency=p95_latency,
                p50_latency=p50_latency
            ))

        return services

    def get_dependency_metrics(self, time_window: str = "5m") -> List[DependencyMetrics]:
        """Get metrics for service-to-service communication"""
        dependencies = []

        # Inter-service request rate
        dep_query = f'sum(rate(istio_requests_total[{time_window}])) by (source_app, destination_service_name)'
        dep_data = self.query_prometheus(dep_query)

        # Success rate
        success_query = f'sum(rate(istio_requests_total{{response_code=~"2.."}}[{time_window}])) by (source_app, destination_service_name)'
        success_data = self.query_prometheus(success_query)

        # Average latency
        latency_query = f'sum(rate(istio_request_duration_milliseconds_sum[{time_window}])) by (source_app, destination_service_name) / sum(rate(istio_request_duration_milliseconds_count[{time_window}])) by (source_app, destination_service_name)'
        latency_data = self.query_prometheus(latency_query)

        # Process results
        for result in dep_data.get('data', {}).get('result', []):
            source = result['metric']['source_app']
            destination = result['metric']['destination_service_name']
            request_rate = float(result['value'][1])

            # Find corresponding success rate and latency
            success_rate = self._extract_dependency_metric(success_data, source, destination)
            avg_latency = self._extract_dependency_metric(latency_data, source, destination)

            dependencies.append(DependencyMetrics(
                source=source,
                destination=destination,
                request_rate=request_rate,
                success_rate=success_rate / max(request_rate, 1) * 100,
                avg_latency=avg_latency
            ))

        return dependencies

    def _extract_metric_value(self, data: Dict, service_name: str) -> float:
        """Extract metric value for specific service"""
        for result in data.get('data', {}).get('result', []):
            if result['metric'].get('destination_service_name') == service_name:
                return float(result['value'][1])
        return 0.0

    def _extract_dependency_metric(self, data: Dict, source: str, destination: str) -> float:
        """Extract metric value for specific dependency"""
        for result in data.get('data', {}).get('result', []):
            metric = result['metric']
            if (metric.get('source_app') == source and
                metric.get('destination_service_name') == destination):
                return float(result['value'][1])
        return 0.0

    def identify_problematic_dependencies(self, dependencies: List[DependencyMetrics]) -> List[DependencyMetrics]:
        """Identify dependencies with issues"""
        problematic = []

        for dep in dependencies:
            if (dep.success_rate < 95 or  # Less than 95% success rate
                dep.avg_latency > 1000 or  # More than 1 second average latency
                dep.request_rate > 1000):   # Very high request rate (potential abuse)
                problematic.append(dep)

        return problematic

    def generate_dependency_report(self) -> Dict:
        """Generate comprehensive dependency report"""
        service_metrics = self.get_service_metrics()
        dependency_metrics = self.get_dependency_metrics()
        problematic_deps = self.identify_problematic_dependencies(dependency_metrics)

        report = {
            'timestamp': time.time(),
            'total_services': len(service_metrics),
            'total_dependencies': len(dependency_metrics),
            'problematic_dependencies': len(problematic_deps),
            'service_health_summary': {
                'healthy': len([s for s in service_metrics if s.error_rate < 1]),
                'degraded': len([s for s in service_metrics if 1 <= s.error_rate < 5]),
                'unhealthy': len([s for s in service_metrics if s.error_rate >= 5])
            },
            'top_services_by_traffic': sorted(service_metrics, key=lambda x: x.request_rate, reverse=True)[:10],
            'highest_latency_services': sorted(service_metrics, key=lambda x: x.p99_latency, reverse=True)[:10],
            'problematic_dependencies': problematic_deps
        }

        return report

# Usage
analyzer = ServiceMeshAnalyzer('http://prometheus:9090')
report = analyzer.generate_dependency_report()

print(f"Service Mesh Health Report:")
print(f"Total services: {report['total_services']}")
print(f"Total dependencies: {report['total_dependencies']}")
print(f"Problematic dependencies: {report['problematic_dependencies']}")
print(f"Service health: {report['service_health_summary']}")
```

## Common Dependency Issues & Solutions

### Pattern 1: Cascading Failures
```python
# Cascading failure detection
def detect_cascading_failure(service_metrics, dependency_metrics):
    cascading_failures = []

    # Look for services with high error rates
    failing_services = [s for s in service_metrics if s.error_rate > 10]

    for failing_service in failing_services:
        # Find services that depend on this failing service
        dependent_services = [d for d in dependency_metrics
                            if d.destination == failing_service.name]

        # Check if dependent services are also failing
        failing_dependents = []
        for dep in dependent_services:
            dependent_health = next((s for s in service_metrics
                                  if s.name == dep.source), None)
            if dependent_health and dependent_health.error_rate > 5:
                failing_dependents.append(dep.source)

        if len(failing_dependents) > 0:
            cascading_failures.append({
                'root_cause_service': failing_service.name,
                'affected_services': failing_dependents,
                'cascade_severity': len(failing_dependents)
            })

    return cascading_failures
```

### Pattern 2: Circuit Breaker Configuration
```yaml
# Resilience4j circuit breaker configuration
resilience4j:
  circuitbreaker:
    instances:
      payment-service:
        failure-rate-threshold: 50
        wait-duration-in-open-state: 30s
        sliding-window-size: 10
        minimum-number-of-calls: 5
        permitted-number-of-calls-in-half-open-state: 3
      database:
        failure-rate-threshold: 60
        wait-duration-in-open-state: 60s
        sliding-window-size: 20
        minimum-number-of-calls: 10
```

## Escalation Criteria

| Dependency Type | Impact Level | Time to Escalate | Contact |
|-----------------|--------------|------------------|----------|
| Critical Database | Service outage | 5 minutes | @database-team |
| External API | Feature degraded | 15 minutes | @integration-team |
| Internal Service | Partial functionality | 10 minutes | @service-owners |
| Infrastructure | System instability | 8 minutes | @platform-team |

## Success Metrics

- **Mapping Accuracy**: 95% of dependencies correctly identified
- **Detection Speed**: < 8 minutes for dependency issues
- **MTTR**: Mean time to resolution < 30 minutes
- **Resilience Improvement**: 60% reduction in cascade failures

*Based on production service dependency practices from Uber, Airbnb, Netflix, and microservices architecture teams.*