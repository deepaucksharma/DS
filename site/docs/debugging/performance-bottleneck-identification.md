# Performance Bottleneck Identification - Production Debugging Guide

## Overview

This guide provides systematic workflows for identifying performance bottlenecks in distributed systems. Based on Google's SRE practices and Netflix's performance debugging methodologies.

**Time to Resolution**: 10-40 minutes for most bottlenecks
**Identification Success Rate**: 95% of bottlenecks located
**False Positive Rate**: <5%

## 1. Complete Performance Bottleneck Investigation Flow

```mermaid
flowchart TD
    PerfDegradation[‚ö° Performance Degradation<br/>SLA breach detected] --> ScopeIdentification[1. Scope Identification<br/>Affected services & users<br/>‚è±Ô∏è 3 min]

    ScopeIdentification --> MetricBaseline[2. Metric Baseline Comparison<br/>Current vs historical performance<br/>‚è±Ô∏è 5 min]

    MetricBaseline --> BottleneckCategories[3. Bottleneck Categories<br/>Primary investigation paths<br/>‚è±Ô∏è 2 min]

    BottleneckCategories --> CPUBottleneck[CPU Bound<br/>High CPU utilization]
    BottleneckCategories --> MemoryBottleneck[Memory Bound<br/>Memory pressure/leaks]
    BottleneckCategories --> IOBottleneck[I/O Bound<br/>Disk/Network constraints]
    BottleneckCategories --> ConcurrencyBottleneck[Concurrency Bound<br/>Lock contention/blocking]
    BottleneckCategories --> ExternalBottleneck[External Bound<br/>Dependencies/APIs]

    CPUBottleneck --> CPUAnalysis[4a. CPU Analysis<br/>‚Ä¢ Profiling & hot spots<br/>‚Ä¢ GC pressure analysis<br/>‚Ä¢ Algorithm efficiency<br/>‚è±Ô∏è 15 min]

    MemoryBottleneck --> MemoryAnalysis[4b. Memory Analysis<br/>‚Ä¢ Heap dump analysis<br/>‚Ä¢ Memory leak detection<br/>‚Ä¢ Allocation patterns<br/>‚è±Ô∏è 20 min]

    IOBottleneck --> IOAnalysis[4c. I/O Analysis<br/>‚Ä¢ Disk throughput/latency<br/>‚Ä¢ Network bandwidth<br/>‚Ä¢ Connection pools<br/>‚è±Ô∏è 12 min]

    ConcurrencyBottleneck --> ConcurrencyAnalysis[4d. Concurrency Analysis<br/>‚Ä¢ Thread dump analysis<br/>‚Ä¢ Lock contention<br/>‚Ä¢ Deadlock detection<br/>‚è±Ô∏è 18 min]

    ExternalBottleneck --> ExternalAnalysis[4e. External Analysis<br/>‚Ä¢ Dependency latency<br/>‚Ä¢ API rate limiting<br/>‚Ä¢ Circuit breaker status<br/>‚è±Ô∏è 10 min]

    CPUAnalysis --> OptimizationPlan[5. Optimization Plan<br/>Targeted fixes & improvements<br/>‚è±Ô∏è 8 min]
    MemoryAnalysis --> OptimizationPlan
    IOAnalysis --> OptimizationPlan
    ConcurrencyAnalysis --> OptimizationPlan
    ExternalAnalysis --> OptimizationPlan

    OptimizationPlan --> ValidationTest[6. Validation Testing<br/>Verify performance improvement<br/>‚è±Ô∏è 15 min]

    ValidationTest --> MonitoringSetup[7. Long-term Monitoring<br/>Prevent regression<br/>‚è±Ô∏è 5 min]

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class PerfDegradation,ScopeIdentification edgeStyle
    class CPUAnalysis,MemoryAnalysis,ConcurrencyAnalysis serviceStyle
    class IOAnalysis,ExternalAnalysis,MetricBaseline stateStyle
    class OptimizationPlan,ValidationTest,MonitoringSetup controlStyle
```

## 2. Google-Style CPU Bottleneck Analysis

```mermaid
flowchart TD
    CPUAlert[üî• CPU Bottleneck Alert<br/>CPU > 85% for 5+ minutes] --> CPUProfiler[1. CPU Profiler Activation<br/>Java: async-profiler<br/>Go: pprof<br/>Python: py-spy<br/>‚è±Ô∏è 2 min]

    CPUProfiler --> FlameGraph[2. Flame Graph Generation<br/>Visualize call stack hotspots<br/>‚è±Ô∏è 3 min]

    FlameGraph --> HotspotAnalysis[3. Hotspot Analysis<br/>Top CPU-consuming methods<br/>‚è±Ô∏è 5 min]

    HotspotAnalysis --> HotspotType{Hotspot<br/>Category?}

    HotspotType --> GCHotspot[GC/Memory Management<br/>>50% GC time]
    HotspotType --> AlgorithmHotspot[Algorithm Inefficiency<br/>O(n¬≤) operations]
    HotspotType --> IOWaitHotspot[I/O Wait Time<br/>Blocking operations]
    HotspotType --> LockHotspot[Lock Contention<br/>Synchronization overhead]

    GCHotspot --> GCAnalysis[4a. GC Analysis<br/>‚Ä¢ Heap sizing issues<br/>‚Ä¢ GC algorithm tuning<br/>‚Ä¢ Memory allocation patterns<br/>‚è±Ô∏è 12 min]

    AlgorithmHotspot --> AlgorithmAnalysis[4b. Algorithm Analysis<br/>‚Ä¢ Big O complexity review<br/>‚Ä¢ Data structure optimization<br/>‚Ä¢ Caching opportunities<br/>‚è±Ô∏è 15 min]

    IOWaitHotspot --> IOWaitAnalysis[4c. I/O Wait Analysis<br/>‚Ä¢ Async operation conversion<br/>‚Ä¢ Connection pooling<br/>‚Ä¢ Timeout optimization<br/>‚è±Ô∏è 10 min]

    LockHotspot --> LockAnalysis[4d. Lock Analysis<br/>‚Ä¢ Lock-free alternatives<br/>‚Ä¢ Critical section reduction<br/>‚Ä¢ Thread pool tuning<br/>‚è±Ô∏è 14 min]

    GCAnalysis --> CPUOptimization[5. CPU Optimization<br/>Apply targeted fixes<br/>‚è±Ô∏è 20 min]
    AlgorithmAnalysis --> CPUOptimization
    IOWaitAnalysis --> CPUOptimization
    LockAnalysis --> CPUOptimization

    CPUOptimization --> LoadTesting[6. Load Testing<br/>Validate improvements<br/>‚è±Ô∏è 15 min]

    LoadTesting --> CPUMonitoring[7. Enhanced CPU Monitoring<br/>Method-level metrics<br/>‚è±Ô∏è 5 min]

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class CPUAlert,CPUProfiler edgeStyle
    class GCAnalysis,AlgorithmAnalysis,LockAnalysis serviceStyle
    class IOWaitAnalysis,FlameGraph,LoadTesting stateStyle
    class CPUOptimization,CPUMonitoring,HotspotAnalysis controlStyle
```

## 3. Netflix-Style Memory Bottleneck Investigation

```mermaid
flowchart TD
    MemoryIssue[üíæ Memory Issue Detected<br/>Memory usage >90% or OOM] --> MemorySnapshot[1. Memory Snapshot<br/>Heap dump capture<br/>‚è±Ô∏è 3 min]

    MemorySnapshot --> HeapAnalysis[2. Heap Analysis<br/>MAT, VisualVM, or jstat<br/>‚è±Ô∏è 8 min]

    HeapAnalysis --> MemoryPattern{Memory Usage<br/>Pattern?}

    MemoryPattern --> MemoryLeak[Memory Leak<br/>Continuous growth]
    MemoryPattern --> MemorySpike[Memory Spike<br/>Sudden allocation]
    MemoryPattern --> MemoryPressure[Memory Pressure<br/>High allocation rate]
    MemoryPattern --> MemoryFragmentation[Memory Fragmentation<br/>Available but unusable]

    MemoryLeak --> LeakAnalysis[3a. Memory Leak Analysis<br/>‚Ä¢ Object retention paths<br/>‚Ä¢ Reference chain analysis<br/>‚Ä¢ Weak reference audit<br/>‚è±Ô∏è 20 min]

    MemorySpike --> SpikeAnalysis[3b. Memory Spike Analysis<br/>‚Ä¢ Large object allocation<br/>‚Ä¢ Batch processing issues<br/>‚Ä¢ Cache warming problems<br/>‚è±Ô∏è 12 min]

    MemoryPressure --> PressureAnalysis[3c. Pressure Analysis<br/>‚Ä¢ Allocation rate tracking<br/>‚Ä¢ GC frequency analysis<br/>‚Ä¢ Object lifecycle review<br/>‚è±Ô∏è 15 min]

    MemoryFragmentation --> FragmentationAnalysis[3d. Fragmentation Analysis<br/>‚Ä¢ Heap compaction issues<br/>‚Ä¢ Large object allocation<br/>‚Ä¢ Memory pool sizing<br/>‚è±Ô∏è 10 min]

    LeakAnalysis --> LeakIdentification[4. Leak Source Identification<br/>Specific classes/methods<br/>‚è±Ô∏è 8 min]
    SpikeAnalysis --> LeakIdentification
    PressureAnalysis --> LeakIdentification
    FragmentationAnalysis --> LeakIdentification

    LeakIdentification --> MemoryFix[5. Memory Fix Implementation<br/>‚Ä¢ Fix memory leaks<br/>‚Ä¢ Optimize allocations<br/>‚Ä¢ Tune GC parameters<br/>‚è±Ô∏è 25 min]

    MemoryFix --> MemoryValidation[6. Memory Validation<br/>‚Ä¢ Heap growth monitoring<br/>‚Ä¢ GC metrics verification<br/>‚Ä¢ Allocation rate check<br/>‚è±Ô∏è 12 min]

    MemoryValidation --> MemoryAlerting[7. Memory Alerting Setup<br/>Trend-based monitoring<br/>‚è±Ô∏è 5 min]

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class MemoryIssue,MemorySnapshot edgeStyle
    class LeakAnalysis,SpikeAnalysis,PressureAnalysis serviceStyle
    class FragmentationAnalysis,HeapAnalysis,MemoryValidation stateStyle
    class LeakIdentification,MemoryFix,MemoryAlerting controlStyle
```

## 4. Uber-Style I/O Bottleneck Diagnosis

```mermaid
flowchart TD
    IOBottleneck[üîÑ I/O Bottleneck<br/>High latency or throughput issues] --> IOMetrics[1. I/O Metrics Collection<br/>‚Ä¢ Disk IOPS & throughput<br/>‚Ä¢ Network bandwidth & latency<br/>‚Ä¢ Connection pool stats<br/>‚è±Ô∏è 4 min]

    IOMetrics --> IOCategorization[2. I/O Categorization<br/>Identify primary constraint<br/>‚è±Ô∏è 3 min]

    IOCategorization --> DiskIO{Disk I/O<br/>Bottleneck?}
    IOCategorization --> NetworkIO{Network I/O<br/>Bottleneck?}
    IOCategorization --> DatabaseIO{Database I/O<br/>Bottleneck?}

    DiskIO -->|Yes| DiskAnalysis[3a. Disk Analysis<br/>‚Ä¢ Disk utilization >85%<br/>‚Ä¢ Queue depth analysis<br/>‚Ä¢ File system performance<br/>‚è±Ô∏è 10 min]

    NetworkIO -->|Yes| NetworkAnalysis[3b. Network Analysis<br/>‚Ä¢ Bandwidth saturation<br/>‚Ä¢ Packet loss detection<br/>‚Ä¢ Connection limits<br/>‚è±Ô∏è 8 min]

    DatabaseIO -->|Yes| DatabaseAnalysis[3c. Database Analysis<br/>‚Ä¢ Query performance<br/>‚Ä¢ Connection pooling<br/>‚Ä¢ Lock wait analysis<br/>‚è±Ô∏è 15 min]

    DiskAnalysis --> DiskBottleneckType{Disk Bottleneck<br/>Type?}
    DiskBottleneckType --> SlowDisk[Slow Disk<br/>High latency reads/writes]
    DiskBottleneckType --> DiskThroughput[Disk Throughput<br/>IOPS saturation]
    DiskBottleneckType --> DiskSpace[Disk Space<br/>Storage exhaustion]

    NetworkAnalysis --> NetworkBottleneckType{Network Bottleneck<br/>Type?}
    NetworkBottleneckType --> Bandwidth[Bandwidth<br/>Throughput saturation]
    NetworkBottleneckType --> Latency[Latency<br/>Round-trip delays]
    NetworkBottleneckType --> ConnectionPool[Connection Pool<br/>Pool exhaustion]

    DatabaseAnalysis --> DatabaseBottleneckType{Database Bottleneck<br/>Type?}
    DatabaseBottleneckType --> SlowQuery[Slow Queries<br/>Query optimization needed]
    DatabaseBottleneckType --> LockContention[Lock Contention<br/>Database blocking]
    DatabaseBottleneckType --> ConnectionLimit[Connection Limit<br/>Pool size issues]

    SlowDisk --> IOOptimization[4. I/O Optimization<br/>Apply targeted fixes<br/>‚è±Ô∏è 20 min]
    DiskThroughput --> IOOptimization
    DiskSpace --> IOOptimization
    Bandwidth --> IOOptimization
    Latency --> IOOptimization
    ConnectionPool --> IOOptimization
    SlowQuery --> IOOptimization
    LockContention --> IOOptimization
    ConnectionLimit --> IOOptimization

    IOOptimization --> IOValidation[5. I/O Validation<br/>Performance measurement<br/>‚è±Ô∏è 10 min]

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class IOBottleneck,IOMetrics edgeStyle
    class DiskAnalysis,NetworkAnalysis,SlowQuery serviceStyle
    class DatabaseAnalysis,IOCategorization,LockContention stateStyle
    class IOOptimization,IOValidation,DatabaseBottleneckType controlStyle
```

## 5. LinkedIn-Style Concurrency Bottleneck Analysis

```mermaid
flowchart TD
    ConcurrencyIssue[üîí Concurrency Issue<br/>High response time with low CPU] --> ThreadDump[1. Thread Dump Collection<br/>Multiple snapshots 30s apart<br/>‚è±Ô∏è 2 min]

    ThreadDump --> ThreadAnalysis[2. Thread State Analysis<br/>BLOCKED, WAITING, RUNNABLE<br/>‚è±Ô∏è 5 min]

    ThreadAnalysis --> ThreadStates{Thread State<br/>Distribution?}

    ThreadStates --> BlockedThreads[BLOCKED Threads<br/>>50% threads blocked]
    ThreadStates --> WaitingThreads[WAITING Threads<br//>High waiting percentage]
    ThreadStates --> RunnableThreads[RUNNABLE Threads<br/>CPU-bound operations]

    BlockedThreads --> LockAnalysis[3a. Lock Contention Analysis<br/>‚Ä¢ Identify lock owners<br/>‚Ä¢ Lock holding time<br/>‚Ä¢ Critical sections<br/>‚è±Ô∏è 12 min]

    WaitingThreads --> WaitAnalysis[3b. Wait Analysis<br/>‚Ä¢ I/O wait operations<br/>‚Ä¢ Condition variables<br/>‚Ä¢ Semaphore bottlenecks<br/>‚è±Ô∏è 10 min]

    RunnableThreads --> CPUAnalysis[3c. CPU Bound Analysis<br/>‚Ä¢ Hot code paths<br/>‚Ä¢ Algorithm efficiency<br/>‚Ä¢ Thread pool sizing<br/>‚è±Ô∏è 8 min]

    LockAnalysis --> LockHotspots[4. Lock Hotspot Identification<br/>Most contended locks<br/>‚è±Ô∏è 6 min]

    WaitAnalysis --> WaitHotspots[4. Wait Hotspot Identification<br/>Longest wait operations<br/>‚è±Ô∏è 4 min]

    CPUAnalysis --> CPUHotspots[4. CPU Hotspot Identification<br/>CPU-intensive operations<br/>‚è±Ô∏è 6 min]

    LockHotspots --> ConcurrencyOptimization[5. Concurrency Optimization<br/>‚Ä¢ Lock-free algorithms<br/>‚Ä¢ Reduced critical sections<br/>‚Ä¢ Better thread pooling<br/>‚è±Ô∏è 25 min]

    WaitHotspots --> ConcurrencyOptimization
    CPUHotspots --> ConcurrencyOptimization

    ConcurrencyOptimization --> ConcurrencyTesting[6. Concurrency Testing<br/>‚Ä¢ Load testing<br/>‚Ä¢ Stress testing<br/>‚Ä¢ Race condition checks<br/>‚è±Ô∏è 20 min]

    ConcurrencyTesting --> ConcurrencyMonitoring[7. Concurrency Monitoring<br/>Thread pool metrics<br/>‚è±Ô∏è 5 min]

    %% Apply 4-plane colors
    classDef edgeStyle fill:#0066CC,stroke:#004499,color:#fff
    classDef serviceStyle fill:#00AA00,stroke:#007700,color:#fff
    classDef stateStyle fill:#FF8800,stroke:#CC6600,color:#fff
    classDef controlStyle fill:#CC0000,stroke:#990000,color:#fff

    class ConcurrencyIssue,ThreadDump edgeStyle
    class LockAnalysis,WaitAnalysis,CPUAnalysis serviceStyle
    class ThreadAnalysis,LockHotspots,WaitHotspots stateStyle
    class ConcurrencyOptimization,ConcurrencyTesting,ConcurrencyMonitoring controlStyle
```

## Production Tool Commands & Configurations

### CPU Profiling Tools
```bash
# Java async-profiler
java -jar async-profiler.jar -e cpu -d 60 -f cpu-profile.html <pid>

# Go pprof CPU profiling
curl http://localhost:6060/debug/pprof/profile?seconds=30 -o cpu.prof
go tool pprof cpu.prof

# Python py-spy profiling
py-spy record -o profile.svg -d 60 -p <pid>

# Linux perf profiling
perf record -g -p <pid> sleep 60
perf report --stdio
```

### Memory Analysis Tools
```bash
# Java heap dump
jcmd <pid> GC.run_finalization
jcmd <pid> VM.gc
jmap -dump:format=b,file=heap.hprof <pid>

# Go memory profiling
curl http://localhost:6060/debug/pprof/heap -o heap.prof
go tool pprof heap.prof

# Python memory profiling
python -m memory_profiler script.py
```

### I/O Performance Monitoring
```bash
# Disk I/O monitoring
iostat -x 1 10
iotop -aoP
sar -d 1 10

# Network I/O monitoring
iftop -i eth0
nethogs -p eth0
ss -tuln | wc -l  # Connection count

# Database connection monitoring
# PostgreSQL
SELECT count(*) FROM pg_stat_activity;
SELECT state, count(*) FROM pg_stat_activity GROUP BY state;

# MySQL
SHOW PROCESSLIST;
SHOW STATUS LIKE 'Threads_connected';
```

### Thread Analysis Tools
```bash
# Java thread dumps
jstack <pid> > threaddump.txt
jcmd <pid> Thread.print > threaddump.txt

# Kill -3 signal for thread dump
kill -3 <pid>

# Thread dump analysis with Eclipse MAT
# Import threaddump.txt into Eclipse MAT

# Go goroutine profiling
curl http://localhost:6060/debug/pprof/goroutine -o goroutines.prof
go tool pprof goroutines.prof
```

## 6. Production Bottleneck Identification Examples

### Netflix CPU Bottleneck Query
```java
// JFR (Java Flight Recorder) analysis
public class CPUBottleneckAnalyzer {
    public void analyzeCPUHotspots(RecordingFile recording) {
        Map<String, Long> methodCpuTime = new HashMap<>();

        while (recording.hasMoreEvents()) {
            RecordedEvent event = recording.readEvent();
            if (event.getEventType().getName().equals("jdk.ExecutionSample")) {
                RecordedStackTrace stackTrace = event.getStackTrace();
                if (stackTrace != null) {
                    String method = stackTrace.getFrames().get(0).getMethod().getName();
                    methodCpuTime.merge(method, 1L, Long::sum);
                }
            }
        }

        // Sort by CPU time and identify hotspots
        methodCpuTime.entrySet().stream()
                .sorted(Map.Entry.<String, Long>comparingByValue().reversed())
                .limit(10)
                .forEach(entry ->
                    System.out.println(entry.getKey() + ": " + entry.getValue()));
    }
}
```

### Uber Memory Leak Detection
```python
# Memory growth rate analysis
import psutil
import time
import matplotlib.pyplot as plt

def monitor_memory_growth(pid, duration=3600):
    process = psutil.Process(pid)
    memory_samples = []
    timestamps = []

    start_time = time.time()
    while time.time() - start_time < duration:
        memory_info = process.memory_info()
        memory_samples.append(memory_info.rss / 1024 / 1024)  # MB
        timestamps.append(time.time())
        time.sleep(60)  # Sample every minute

    # Calculate memory growth rate
    if len(memory_samples) > 2:
        growth_rate = (memory_samples[-1] - memory_samples[0]) / (len(memory_samples) - 1)
        print(f"Memory growth rate: {growth_rate:.2f} MB/minute")

        # Plot memory usage
        plt.plot(timestamps, memory_samples)
        plt.xlabel('Time')
        plt.ylabel('Memory Usage (MB)')
        plt.title('Memory Growth Analysis')
        plt.savefig('memory_growth.png')

        return growth_rate > 1.0  # Alert if growing > 1MB/min
    return False
```

### Google I/O Bottleneck Monitoring
```bash
#!/bin/bash
# I/O bottleneck detection script

# Check disk I/O utilization
check_disk_io() {
    local utilization=$(iostat -x 1 2 | awk 'NR==4 {print $10}' | tail -1)
    echo "Disk utilization: ${utilization}%"

    if (( $(echo "$utilization > 85" | bc -l) )); then
        echo "WARNING: High disk utilization detected"

        # Find processes with high I/O
        iotop -a -o -d 1 -n 3 | head -20

        # Check for large files being written
        lsof +L1 | grep -v '(deleted)' | awk '{print $2, $9}' | sort | uniq -c | sort -nr | head -10
    fi
}

# Check network I/O
check_network_io() {
    local bandwidth=$(iftop -t -s 10 2>/dev/null | grep "Total" | awk '{print $2}')
    echo "Network bandwidth usage: $bandwidth"

    # Check connection pool exhaustion
    local connections=$(ss -tuln | wc -l)
    echo "Active connections: $connections"

    if (( connections > 10000 )); then
        echo "WARNING: High connection count detected"
        ss -s  # Show socket statistics
    fi
}

check_disk_io
check_network_io
```

## Common False Positives & Solutions

### 1. Auto-scaling Events (18% of investigations)
```yaml
# Correlation with auto-scaling events
apiVersion: v1
kind: ConfigMap
metadata:
  name: bottleneck-correlation
data:
  check_autoscaling.sh: |
    #!/bin/bash
    # Check if performance issue correlates with scaling
    ANOMALY_TIME=$(date -d "-5 minutes" +%s)

    # Check Kubernetes scaling events
    kubectl get events --field-selector reason=SuccessfulRescale \
      --since=10m -o json | jq '.items[] | select(.firstTimestamp)'

    # Check AWS Auto Scaling
    aws autoscaling describe-scaling-activities \
      --auto-scaling-group-name my-asg \
      --max-items 5
```

### 2. JIT Compilation Warmup (12% of investigations)
```java
// JIT compilation monitoring
public class JITWarmupMonitor {
    private static final long WARMUP_THRESHOLD = 300000; // 5 minutes

    public boolean isJITWarming() {
        RuntimeMXBean runtimeBean = ManagementFactory.getRuntimeMXBean();
        long uptime = runtimeBean.getUptime();

        if (uptime < WARMUP_THRESHOLD) {
            CompilationMXBean compilationBean = ManagementFactory.getCompilationMXBean();
            long compilationTime = compilationBean.getTotalCompilationTime();

            // High compilation activity indicates JIT warmup
            return compilationTime > (uptime * 0.1); // >10% time compiling
        }
        return false;
    }
}
```

### 3. Garbage Collection Pauses (15% of investigations)
```bash
# GC analysis script
analyze_gc_logs() {
    local gc_log="$1"

    # Parse GC logs for long pauses
    grep -E "GC|pause" "$gc_log" | awk '
    /pause/ {
        # Extract pause time
        if (match($0, /[0-9]+\.[0-9]+ms/)) {
            pause = substr($0, RSTART, RLENGTH-2)
            if (pause > 100) {
                print "Long GC pause: " pause "ms at " $1 " " $2
            }
        }
    }'

    # Calculate average GC frequency
    total_gcs=$(grep -c "GC" "$gc_log")
    log_duration=$(head -1 "$gc_log" | awk '{print $1}')
    end_time=$(tail -1 "$gc_log" | awk '{print $1}')

    echo "GC frequency: $((total_gcs / (end_time - log_duration))) GCs per second"
}
```

## Escalation Criteria

| Investigation Time | Escalation Action | Contact |
|-------------------|------------------|----------|
| 30 minutes | Senior Engineer | @oncall-senior |
| 60 minutes | Performance Team | @perf-team |
| 90 minutes | War Room | @incident-commander |
| 2 hours | External Expert | @performance-consultant |

## Success Metrics

- **Identification Rate**: 95% of bottlenecks correctly identified
- **MTTR**: Mean time to resolution < 40 minutes
- **False Positive Rate**: < 5% of investigations
- **Prevention Rate**: 80% reduction in similar bottlenecks

*Based on production performance debugging practices from Google, Netflix, Uber, and LinkedIn engineering teams.*